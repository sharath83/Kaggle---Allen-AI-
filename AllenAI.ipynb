{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from math import log\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare tfidf index for corpus (ck12 text books of relevant topics downloaded from web)\n",
    "# read data\n",
    "# get question from every row\n",
    "# get the closest paragraphs for the question\n",
    "# get the best matched answer for the closest paragraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocess the line. \n",
    "def preprocess(line):\n",
    "    #remove stop words, all symbols and numbers and split the line in to words\n",
    "    line = re.sub(\"[^a-zA-Z]\",\" \",line)\n",
    "    line = line.lower().split()\n",
    "    \n",
    "    #remove stopwords\n",
    "    stops = stopwords.words(\"english\")\n",
    "    line = [word for word in line if not word in stops]\n",
    "    \n",
    "    #stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    line = [stemmer.stem(word) for word in line]\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get closest paragraphs from the corpus given a qst and tfidf of corpus\n",
    "def get_closest_para_for_qst(qst, para_tf, idf):\n",
    "    matched_para = []\n",
    "    for para_name, para in para_tf.items():\n",
    "        w_in_para_score = 0\n",
    "        for word in qst:\n",
    "            if word in para:\n",
    "                w_in_para_score += 0.05 * para_tf[para_name][word] * idf[word]\n",
    "        \n",
    "        if w_in_para_score > 0:\n",
    "            matched_para.append((para, w_in_para_score))\n",
    "    \n",
    "    #Get best matched para for the qst. Paragraph with highest score are the best matched ones with the qst\n",
    "    matched_para = sorted(matched_para, key = lambda k: k[1], reverse = True)\n",
    "    return matched_para[:5] #Return top 3 matched paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the corpus - ck12 text books\n",
    "path = '/Users/homw/Documents/petp/AllenAI/Concepts - CK-12 Foundation.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "# Initialize a dictionary to keep {line1:{word1:tf, word2:tf...}...}\n",
    "\n",
    "total_words = 0\n",
    "para_tf = {}\n",
    "for index, line in enumerate(open(path)):\n",
    "    \n",
    "    line = preprocess(line)\n",
    "    \n",
    "    if len(line) > 5:\n",
    "        total_line_words = 0 #To keep the count of words in paragraph/line\n",
    "        dic = {}\n",
    "        for word in line:\n",
    "            vocab.add(word)\n",
    "            dic.setdefault(word,0) #add a word to dictionary only if it is not existing\n",
    "            dic[word] = dic[word]+1\n",
    "            total_words = total_words + 1\n",
    "            total_line_words += 1\n",
    "\n",
    "        # Compute term freq for each word in a paragraph\n",
    "        #for word, count in dic.items():\n",
    "            #dic[word] = count\n",
    "        \n",
    "        # store Tf values of each paragraph in a dictionary\n",
    "        para_name = \"para\"+ str(index)\n",
    "        para_tf[para_name] = dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5103ef0f9f49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute idf values for all the words in vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0midf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdocs_has_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpara_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute idf values for all the words in vocabulary\n",
    "idf = {}\n",
    "for word in list(vocab):\n",
    "    docs_has_word = 1\n",
    "    for index,doc in para_tf.items():\n",
    "        if word in doc:\n",
    "            docs_has_word += 1\n",
    "    idf[word] = log(len(para_tf)/docs_has_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "closest_paras = get_closest_para_for_qst(qst, para_tf, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d3747e4d8105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#read the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/homw/Documents/petp/AllenAI/validation_set.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#read the data \n",
    "data = pd.read_csv(\"/Users/homw/Documents/petp/AllenAI/validation_set.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When athletes begin to exercise, their heart rates and respiration rates increase.  At what level of organization does the human body coordinate these functions?'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qst\n",
    "data.question[0]\n",
    "idf[\"respiration\"]\n",
    "data.question[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qst = preprocess(data.question[0])\n",
    "qst\n",
    "closest_paras\n",
    "#closest_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 499\n",
      "1000 999\n",
      "1500 1499\n",
      "2000 1999\n",
      "2500 2499\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "missed = 0\n",
    "for index, record in data.iterrows():\n",
    "    #print(index, record)\n",
    "    qst = preprocess(record[\"question\"])\n",
    "    closest_paras = get_closest_para_for_qst(qst, para_tf, idf) #Get only the paragraph, score is not required\n",
    "    # Now check which of the options out of A,B,C,D scores highest with the best matched paragraphs of the Qst\n",
    "    \n",
    "    opt_A = preprocess(record[\"answerA\"])\n",
    "    score_A = 0\n",
    "    for word in opt_A:\n",
    "        for para, score in list(closest_paras):\n",
    "            if word in para:\n",
    "                score_A += para[word] * idf[word]\n",
    "                \n",
    "    \n",
    "    opt_B = preprocess(record[\"answerB\"])\n",
    "    score_B = 0\n",
    "    for word in opt_B:\n",
    "        for para, score in list(closest_paras):\n",
    "            if word in para:\n",
    "                score_B += para[word] * idf[word]\n",
    "\n",
    "                \n",
    "    \n",
    "    opt_C = preprocess(record[\"answerC\"])\n",
    "    score_C = 0\n",
    "    for word in opt_C:\n",
    "        for para, score in list(closest_paras):\n",
    "            if word in para:\n",
    "                score_C += para[word] * idf[word]\n",
    "\n",
    "                \n",
    "    \n",
    "    opt_D = preprocess(record[\"answerD\"])\n",
    "    score_D = 0\n",
    "    for word in opt_D:\n",
    "        for para, score in list(closest_paras):\n",
    "            if word in para:\n",
    "                score_D += para[word] * idf[word]\n",
    "\n",
    "    if all([score_A,score_B,score_C,score_D]) == 0:\n",
    "        prediction.append(\"N\")\n",
    "        missed += 1\n",
    "    else:\n",
    "        prediction.append([\"A\",\"B\",\"C\",\"D\"] [np.argmax([score_A,score_B,score_C,score_D])])\n",
    "    if len(prediction)%500 == 0:\n",
    "        print(len(prediction), index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([1 for i, j in zip(prediction, data.correctAnswer) if i == j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove items from dictionary - This part is not used\n",
    "small_para = [k for k,p in para_tf.items() if len(p) <= 5]\n",
    "for k in small_para: del para_tf[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'question', 'correctAnswer', 'answerA', 'answerB', 'answerC',\n",
       "       'answerD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07142857142857142"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'id': list(data['id']), 'correctAnswer': prediction})[['id', 'correctAnswer']].to_csv(\"sub2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all([0,0,0])==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27879999999999999"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(prediction == data[\"correctAnswer\"])/2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "a = 22\n",
    "b = 4\n",
    "check=min(a,b)\n",
    "gcd=max(a,b)\n",
    "while(check != 0):\n",
    "     \n",
    "    x = gcd % check\n",
    "    gcd = check\n",
    "    check = x\n",
    "    \n",
    "print(gcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am     inch shorter than the random guy x   as   '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = \"I am 2.5 inch shorter than the random guy x@# as678\"\n",
    "line = re.sub(\"[^a-zA-Z]\",\" \",line)\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "coercing to Unicode: need string or buffer, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-963a2d511461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjsonf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjsondoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ISO-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mjsonf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: coercing to Unicode: need string or buffer, list found"
     ]
    }
   ],
   "source": [
    "with open(path, \"r\") as jsonf:\n",
    "    jsondoc = json.loads(unicode(jsonf.readlines(), \"ISO-8859-1\"))\n",
    "jsonf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "path = '/Users/homw/Documents/MSDS16/textmining/yelp/query/query.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dot(a,b):\n",
    "    return sum([(ai*bi) for ai,bi in zip(a,b)])\n",
    "def cos_sim(a,b):\n",
    "    return dot(a,b)/(np.sqrt(dot(a,a)) * np.sqrt(dot(b,b)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 6146, 0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = [1,2,3,4,4,78,4]\n",
    "b = [0,0,0,0,0]\n",
    "dot(a,b), dot(a,a), dot(b,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/homw/anaconda/envs/python2/lib/python2.7/site-packages/IPython/kernel/__main__.py:4: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10, 0, 0, 0, 0, 12]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(ai*bi) for ai,bi in zip(a,b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
